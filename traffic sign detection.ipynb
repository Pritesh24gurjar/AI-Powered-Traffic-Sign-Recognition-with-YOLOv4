{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 28, 28, 6)         156       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 400)               0         \n_________________________________________________________________\ndense (Dense)                (None, 120)               48120     \n_________________________________________________________________\ndense_1 (Dense)              (None, 84)                10164     \n_________________________________________________________________\ndropout (Dropout)            (None, 84)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 43)                3655      \n=================================================================\nTotal params: 64,511\nTrainable params: 64,511\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayAndEqualizeHist(img):\n",
    "    \"\"\"\n",
    "\n",
    "    :param img: input RGB image\n",
    "    :return: histogram equalized grayscale image\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
    "    equ  = cv2.equalizeHist(gray)\n",
    "    #equ  = equ - 128. / 128.\n",
    "    return equ\n",
    "\n",
    "\n",
    "img= cv2.imread(\"images/4.png\")\n",
    "# print(img)\n",
    "img = np.asarray(img)\n",
    "# print(img)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "img = grayAndEqualizeHist(img)\n",
    "# cv2.imshow(\"Processed Image\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted sign: [9]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "img = img[...,np.newaxis]\n",
    "# print(img)\n",
    "plt.imshow(img.reshape(32,32))\n",
    "print(\"Predicted sign: \"+ str(new_model.predict_classes(img.reshape(1, 32, 32, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fb7ae92f9c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# PREDICT IMAGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mclassIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mprobabilityValue\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprobabilityValue\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    462\u001b[0m                   \u001b[1;34m'  if your model does binary classification '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                   '  (e.g. if it uses a `sigmoid` last-layer activation).')\n\u001b[1;32m--> 464\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1721\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1723\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1724\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1200\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3120\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    " \n",
    "#############################################\n",
    " \n",
    "frameWidth= 640         # CAMERA RESOLUTION\n",
    "frameHeight = 480\n",
    "brightness = 180\n",
    "threshold = 0.75         # PROBABLITY THRESHOLD\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "##############################################\n",
    " \n",
    "# SETUP THE VIDEO CAMERA\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10, brightness)\n",
    "# IMPORT THE TRANNIED MODEL\n",
    "# pickle_in=open(\"model_trained.p\",\"rb\")  ## rb = READ BYTE\n",
    "# model=pickle.load(pickle_in)\n",
    " \n",
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalize(img):\n",
    "    img =cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "def getCalssName(classNo):\n",
    "    if   classNo == 0: return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1: return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2: return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3: return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4: return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5: return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7: return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8: return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9: return 'No passing'\n",
    "    elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11: return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12: return 'Priority road'\n",
    "    elif classNo == 13: return 'Yield'\n",
    "    elif classNo == 14: return 'Stop'\n",
    "    elif classNo == 15: return 'No vechiles'\n",
    "    elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17: return 'No entry'\n",
    "    elif classNo == 18: return 'General caution'\n",
    "    elif classNo == 19: return 'Dangerous curve to the left'\n",
    "    elif classNo == 20: return 'Dangerous curve to the right'\n",
    "    elif classNo == 21: return 'Double curve'\n",
    "    elif classNo == 22: return 'Bumpy road'\n",
    "    elif classNo == 23: return 'Slippery road'\n",
    "    elif classNo == 24: return 'Road narrows on the right'\n",
    "    elif classNo == 25: return 'Road work'\n",
    "    elif classNo == 26: return 'Traffic signals'\n",
    "    elif classNo == 27: return 'Pedestrians'\n",
    "    elif classNo == 28: return 'Children crossing'\n",
    "    elif classNo == 29: return 'Bicycles crossing'\n",
    "    elif classNo == 30: return 'Beware of ice/snow'\n",
    "    elif classNo == 31: return 'Wild animals crossing'\n",
    "    elif classNo == 32: return 'End of all speed and passing limits'\n",
    "    elif classNo == 33: return 'Turn right ahead'\n",
    "    elif classNo == 34: return 'Turn left ahead'\n",
    "    elif classNo == 35: return 'Ahead only'\n",
    "    elif classNo == 36: return 'Go straight or right'\n",
    "    elif classNo == 37: return 'Go straight or left'\n",
    "    elif classNo == 38: return 'Keep right'\n",
    "    elif classNo == 39: return 'Keep left'\n",
    "    elif classNo == 40: return 'Roundabout mandatory'\n",
    "    elif classNo == 41: return 'End of no passing'\n",
    "    elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'\n",
    "    \n",
    "while True:\n",
    " \n",
    "    # READ IMAGE\n",
    "    success, imgOrignal = cap.read()\n",
    "    \n",
    "    # PROCESS IMAGE\n",
    "    #new\n",
    "    img = np.asarray(imgOrignal)\n",
    "    # print(img)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = grayAndEqualizeHist(img)\n",
    "    cv2.imshow(\"Processed Image\", img)\n",
    "    img = img[...,np.newaxis]\n",
    "    img = img.reshape(1, 32, 32, 1)\n",
    "    #old\n",
    "    # img = np.asarray(imgOrignal)\n",
    "    # img = cv2.resize(img, (32, 32))\n",
    "    # img = preprocessing(img)\n",
    "    # cv2.imshow(\"Processed Image\", img)\n",
    "    # img = img.reshape(1, 32, 32, 1)\n",
    "    cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    # PREDICT IMAGE\n",
    "    predictions = new_model.predict(img)\n",
    "    classIndex = new_model.predict_classes(img)\n",
    "    probabilityValue =np.amax(predictions)\n",
    "    if probabilityValue > threshold:\n",
    "        #print(getCalssName(classIndex))\n",
    "        cv2.putText(imgOrignal,str(classIndex)+\" \"+str(getCalssName(classIndex)), (120, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(imgOrignal, str(round(probabilityValue*100,2) )+\"%\", (180, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Result\", imgOrignal)\n",
    "    \n",
    "    if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}